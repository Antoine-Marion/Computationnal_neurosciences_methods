{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the following development we will tend to reproduce numeralically the results published by Sussillo and Abbott onto their papers: 'Generating Coherent Patterns of Activity from Chaotic Neural Networks'.\n",
    "In order to stuck to easily reproducable and understandable results, our results we be based on a complete coding of the learning algorithm avoiding the use of any previously coded librairies. \n",
    "\n",
    "\n",
    "\n",
    "## Paper abstract reminder\n",
    "\n",
    "Neural circuits display complex activity patterns both spontaneously and when responding to a stimulus or generating a motor output. How are these two forms of activity related? We develop a procedure called FORCE learning for modifying synaptic strengths either external to or within a model neural network to change chaotic spontaneous activity into a wide variety of desired activity patterns. FORCE learning works even though the networks we train are spontaneously chaotic and we leave feedback loops intact and unclamped during learning. Using this approach, we construct networks that produce a wide variety of complex output patterns, input-output transformations that require memory, multiple outputs that can be switched by control inputs, and motor patterns matching human motion capture data. Our results reproduce data on premovement activity in motor and premotor cortex, and suggest that synaptic plasticity may be a more rapid and powerful modulator of network activity than generally appreciated.\n",
    "\n",
    "\n",
    "## Results - (Sussillo and Abbott figure 2 reproduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10645)\n",
    "\n",
    "N_G = 1000 ### mauvaise valeur\n",
    "g_GG = 1.3\n",
    "p_GG = 0.1\n",
    "p_z = 1\n",
    "g_Gz = 1\n",
    "g_GF = 0\n",
    "alpha = 1\n",
    "N_l = 0\n",
    "tau = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_initial_weights(N_G, p_z):  \n",
    "    \"\"\"\n",
    "    w_init = np.zeros(N_G)\n",
    "    for k in range(N_G):\n",
    "        p = np.random.uniform(0, 1, 1)\n",
    "        if p <= p_z:\n",
    "            w_init[k] = np.random.normal(0, 1/np.sqrt(p_z*N_G), 1)\n",
    "     \"\"\"\n",
    "    return np.random.normal(0, np.sqrt(1/N_G), N_G)\n",
    "\n",
    "\n",
    "def define_connection_matrix_J(N, proba):\n",
    "    \"\"\"\n",
    "    J = np.array([np.zeros(N) for j in range(N)])\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            p = np.random.uniform(0, 1, 1)\n",
    "            if p  <= proba:\n",
    "                J[i][j] = np.random.normal(0, 1/(proba*N), 1)\n",
    "    \"\"\"\n",
    "    return np.random.normal(0,np.sqrt(1/(N*proba)), [N, N])\n",
    "\n",
    "def update_x_t_by_euler_method(x, r, z, dt, tau, N_G, g_GG, J_GG, g_Gz, J_Gz):\n",
    "    \"\"\" This function computes x(t+dt) knowing x(t) for every i\n",
    "    This holds for Figure 2 and a simpler version of the differential equation\n",
    "    x_in, r_in and z are functions of t ; tau, N_G, g_GG, J_GG, g_Gz and J_Gz are constants\"\"\"\n",
    "    \n",
    "    x_out = []\n",
    "    \n",
    "    for i in range(N_G):\n",
    "        variation = -x[i] + g_GG * np.dot(J_GG[i], r) + g_Gz * J_Gz[i] * z\n",
    "        variation = variation / tau\n",
    "        x_out.append(x[i] + variation * dt)\n",
    "    \n",
    "    return np.array(x_out)\n",
    "\n",
    "\n",
    "def compute_z(w, r):\n",
    "    \"\"\" w and r as numpy arrays of same size. They are the weights and the \n",
    "    firing rates at time t. The function returns the dot\n",
    "    product of the two, which is the output of the network)\"\"\"\n",
    "    return np.dot(w, r)\n",
    "\n",
    "def compute_error(w_delta, r, f):\n",
    "    \"\"\" The function returns the error (scalar)\"\"\"\n",
    "    return np.dot(w, r) - f\n",
    "\n",
    "def check_decreasing_error(e_minus, e_plus):\n",
    "    if abs(e_plus) <= abs(e_minus):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def modification_rule_weights(w, e_minus, P, r):\n",
    "    \"\"\" w, e_minus and r are column arrays, P is a matrix \n",
    "    w is taken at time t - Delta_t ; the others at time t \"\"\"\n",
    "    w = w - e_minus * np.dot(P, r)\n",
    "    return w\n",
    "\n",
    "def modification_rule_matrix(P, r):\n",
    "    \"\"\" P is a matrix, taken at time t - Delta_t\n",
    "    r is the synaptic array taken at time t \"\"\"\n",
    "    D = np.outer(r, r)\n",
    "    D = np.dot(D, P)\n",
    "    D = np.dot(P, D)\n",
    "    Pr = np.dot(P, r)\n",
    "    a = np.dot(r, Pr)\n",
    "    return P - D/(1 +a)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 4000 #duration in ms\n",
    "dt = 0.05 #time step in ms\n",
    "time = np.arange(0, D, dt)\n",
    "\n",
    "def F1(t, period = 600):\n",
    "    \"\"\" Sinus function\"\"\"\n",
    "    return np.sin(2*np.pi*t/period)\n",
    "\n",
    "def F2(t, period = 600):\n",
    "    \"\"\" Fonction crÃ©neau\"\"\"\n",
    "    if t%period < period/2:\n",
    "        return -1\n",
    "    return 1\n",
    "\n",
    "def F3(t, period = 600):\n",
    "    \"\"\" Fonction triangle\"\"\"\n",
    "    t = t%period\n",
    "    if t < period/2:\n",
    "        return -1 + 2*t/300\n",
    "    return 3 - 2*t/300\n",
    "\n",
    "list_functions = [F1, F2, F3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * End of the spontaneaous activity\n",
      "* * * * "
     ]
    }
   ],
   "source": [
    "\n",
    "J_GG = define_connection_matrix_J(N_G, p_GG)\n",
    "J_Gz = np.random.uniform(-1, 1, N_G)\n",
    "\n",
    "Fx=[]\n",
    "Fy=[]\n",
    "Z = np.zeros(int(D/dt))\n",
    "F = np.zeros(int(D/dt))\n",
    "list_ratio_errors = np.zeros(int(D/dt))\n",
    "list_difference_errors_plus = np.zeros(int(D/dt))\n",
    "\n",
    "\n",
    "# Define initial variables\n",
    "P = np.eye(N_G)/alpha\n",
    "w = define_initial_weights(N_G, p_z)\n",
    "x = np.random.uniform(0, 1, N_G)\n",
    "r = np.tanh(x)\n",
    "z = compute_z(w,r)\n",
    "\n",
    "# Before updating the weigths\n",
    "W=[[],[],[],[]]\n",
    "X=[[],[],[],[]]\n",
    "\n",
    "\n",
    "\n",
    "for F in list_functions[:1]:\n",
    "    \n",
    "    mod = 1\n",
    "    init=True\n",
    "    finish=True\n",
    "    for i in range (0,len(time)):\n",
    "        t=time[i]\n",
    "        f=0\n",
    "        e_minus = compute_error(w, r, f)\n",
    "        if t>D/4 and t<3*D/4 and t%10==0:\n",
    "            if init==True:\n",
    "                print('End of the spontaneaous activity')\n",
    "                init=False\n",
    "            Fx.append(t)\n",
    "            f=F(t)\n",
    "            Fy.append(f)\n",
    "            P = modification_rule_matrix(P, r)\n",
    "            e_minus = compute_error(w, r, f)\n",
    "            w = modification_rule_weights(w, e_minus, P, r)\n",
    "        if t - mod/10*D > 0:\n",
    "            print('*', end = \" \")\n",
    "            mod+=1\n",
    "        if t>3*D/4 and t%10==0 and finish==True:\n",
    "            print('End of the learning phasis')\n",
    "            finish=False\n",
    "    \n",
    "        e_minus = compute_error(w, r, f)\n",
    "    \n",
    "        x = update_x_t_by_euler_method(x, r, z, dt, tau, N_G, g_GG, J_GG, g_Gz, J_Gz)\n",
    "    \n",
    "        r = np.tanh(x)\n",
    "        z = compute_z(w,r)\n",
    "    \n",
    "        Z[i]=(z)\n",
    "    \n",
    "    \n",
    "        for i in range(0,4):\n",
    "            W[i].append(w[i])\n",
    "            X[i].append(x[i])\n",
    "\n",
    "        Pr = np.dot(P, r)\n",
    "        a = np.dot(r, Pr)\n",
    "        e_plus = e_minus*(1-a)\n",
    "\n",
    "        #list_ratio_errors.append(e_plus/e_minus)\n",
    "        list_difference_errors_plus[i]=e_plus\n",
    "\n",
    "print('*')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def settings_all_plots():\n",
    "    \"\"\" Rather than rewriting this everytime\"\"\"\n",
    "    plt.axvline(D/4, -2, 2, color = 'gray', linewidth = 0.7)\n",
    "    plt.axvline(3*D/4, -2, 2, color = 'gray', linewidth = 0.7)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('Relative scale')\n",
    "    plt.legend()\n",
    "\n",
    "residu=[]\n",
    "for sortie,target in zip(Z,F):\n",
    "    residu.append(np.abs(sortie-target))\n",
    "\n",
    "# Main plot\n",
    "plt.figure(figsize = (16, 4))\n",
    "plt.plot(time,Z, color = 'red', label = 'Output')\n",
    "plt.plot(Fx,Fy, color = 'blue', label = 'Target')\n",
    "#plt.plot(time,residu, label='residu')\n",
    "plt.title('Evolution of the network output over time')\n",
    "settings_all_plots()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the activity of four specific weights\n",
    "plt.figure(figsize = (16, 4))\n",
    "for i in range(0,4):\n",
    "    plt.plot(W[i] + 2*i, label = 'Weight #' + str(i))\n",
    "\n",
    "plt.yticks([])\n",
    "settings_all_plots()\n",
    "plt.show()\n",
    "\n",
    "# Plot the activity of four specific activities\n",
    "plt.figure(figsize = (16,4))\n",
    "for i in range(0,5):\n",
    "    plt.plot(X[i] + 2*i, label = 'Neuron #' + str(i))\n",
    "\n",
    "settings_all_plots()\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F[1900:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of FORCE Learning (Sussillo and Abbott figure 3 reproduction)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
